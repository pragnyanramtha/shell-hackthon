{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12405754,"sourceType":"datasetVersion","datasetId":7823452},{"sourceId":12406847,"sourceType":"datasetVersion","datasetId":7824237},{"sourceId":12513943,"sourceType":"datasetVersion","datasetId":7898717},{"sourceId":12521848,"sourceType":"datasetVersion","datasetId":7904076},{"sourceId":12523545,"sourceType":"datasetVersion","datasetId":7905274}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! git clone https://github.com/priorlabs/tabpfn-extensions.git\n! pip install -e tabpfn-extensions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom tabpfn_extensions.post_hoc_ensembles.sklearn_interface import AutoTabPFNRegressor\nimport warnings\n\n# Suppress potential warnings for a cleaner output\nwarnings.filterwarnings(\"ignore\")\n\n# --- 1. Load Data ---\n# Your file paths are correct for Kaggle notebooks.\ntry:\n    train_df = pd.read_csv(\"/kaggle/input/training/train.csv\")\n    test_df = pd.read_csv(\"/kaggle/input/testing/test.csv\")\n    sample_submission_df = pd.read_csv(\"/kaggle/input/samplesubmission/sample_solution.csv\")\nexcept FileNotFoundError as e:\n    print(f\"Error: Could not find data files at the specified Kaggle paths.\")\n    exit()\n\n\n# --- THIS IS THE CORRECTED FEATURE ENGINEERING FUNCTION ---\ndef feature_engineer_v2(df):\n    \"\"\"\n    Creates new features for the model.\n    This version is adapted to the specific column names in your CSV files.\n    \"\"\"\n    # Use the correct column names ending in '_fraction'\n    comp_frac_cols = [\n        'Component1_fraction', 'Component2_fraction', 'Component3_fraction',\n        'Component4_fraction', 'Component5_fraction'\n    ]\n    \n    prop_names = [f'Property{i}' for i in range(1, 11)]\n\n    # Create Weighted Property Features\n    for prop in prop_names:\n        weighted_prop_col_name = f'Weighted_{prop}'\n        df[weighted_prop_col_name] = 0\n        for frac_col in comp_frac_cols:\n            # Updated logic to correctly get the component number (e.g., '1')\n            comp_num = frac_col.split('_')[0].replace('Component', '')\n            # Construct the correct property column name (e.g., 'Component1_Property1')\n            comp_prop_col = f'Component{comp_num}_{prop}'\n            df[weighted_prop_col_name] += df[frac_col] * df[comp_prop_col]\n\n    # Create Interaction Features\n    for i in range(len(comp_frac_cols)):\n        for j in range(i + 1, len(comp_frac_cols)):\n            col1 = comp_frac_cols[i]\n            col2 = comp_frac_cols[j]\n            interaction_col_name = f'{col1}_x_{col2}'\n            df[interaction_col_name] = df[col1] * df[col2]\n            \n    return df\n\n# Apply the CORRECT feature engineering to both training and test data\nX_train_featured = feature_engineer_v2(train_df.copy())\nX_test_featured = feature_engineer_v2(test_df.copy())\n\n\n# --- 2. Prepare Data ---\ntest_ids = X_test_featured['ID']\ny_train = X_train_featured.filter(like=\"Blend\") # Targets are now in the featured DF\n\n# Important: Use the featured dataframes to create X_train and X_test\nX_train = X_train_featured.drop(columns=y_train.columns)\nif 'ID' in X_train.columns:\n    X_train = X_train.drop(columns=['ID'])\nX_test = X_test_featured.drop(columns=['ID'])\n\n# Align columns\nX_test = X_test[X_train.columns]\n\nprint(f\"Number of features after engineering: {X_train.shape[1]}\")\n\n# --- 3. Define and Train TabPFN Model ---\nprint(\"\\nDefining and training TabPFN model on FEATURED data...\")\nbase_worker_model = AutoTabPFNRegressor(device='cuda')\nmulti_output_manager = MultiOutputRegressor(base_worker_model)\nmulti_output_manager.fit(X_train, y_train)\nprint(\"Training complete.\")\n\n\n# --- 4. Make Predictions & Create Submission File ---\nprint(\"Making predictions...\")\npredictions = multi_output_manager.predict(X_test)\nsubmission_df = pd.DataFrame(predictions, columns=sample_submission_df.columns[1:])\nsubmission_df.insert(0, 'ID', test_ids)\nsubmission_df.to_csv(\"submission_tabpfn_featured.csv\", index=False)\n\nprint(\"\\nSubmission file 'submission_tabpfn_featured.csv' has been created successfully.\")\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:21:54.001518Z","iopub.execute_input":"2025-07-20T07:21:54.002053Z","iopub.status.idle":"2025-07-20T09:10:47.211833Z","shell.execute_reply.started":"2025-07-20T07:21:54.002027Z","shell.execute_reply":"2025-07-20T09:10:47.210927Z"}},"outputs":[{"name":"stdout","text":"Number of features after engineering: 75\n\nDefining and training TabPFN model on FEATURED data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tabpfn-v2-regressor.ckpt:   0%|          | 0.00/44.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1c92ae4ca84c9093c502c87aa8a993"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/37.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6b17f02e2ff4cd3b9e7f0e3a30deb2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tabpfn-v2-regressor.ckpt:   0%|          | 0.00/44.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ab026a0fe5b4177826283483c95e8e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/37.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b15afb605d0f400f862c1751de40ef7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tabpfn-v2-regressor-2noar4o2.ckpt:   0%|          | 0.00/44.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"372c297efcd544ac940641b011051637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/37.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d5f9bdc0054297a9f7d52a54418be5"}},"metadata":{}},{"name":"stdout","text":"Training complete.\nMaking predictions...\n\nSubmission file 'submission_tabpfn_featured.csv' has been created successfully.\n   ID  BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n0   1        0.169386        0.222103        0.743162        0.631759   \n1   2       -0.778638       -0.631997       -1.172039        0.037656   \n2   3        1.757005        1.122206        1.063820        1.079432   \n3   4       -0.474016        0.355459        0.969324       -0.739682   \n4   5        0.175554       -1.198867        1.089620        0.481416   \n\n   BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n0        0.353870        0.703197        0.716492        0.390561   \n1       -0.724650       -0.105775       -1.163194       -1.097612   \n2        2.562512        1.868811        1.038993        1.986182   \n3        1.898897       -0.451884        0.921535        1.727649   \n4        2.369047        0.247823        1.045596       -0.146356   \n\n   BlendProperty9  BlendProperty10  \n0       -0.365372         0.334806  \n1       -0.878559         0.022791  \n2        0.768646         2.246833  \n3        0.731011        -0.919113  \n4       -0.428938         1.034190  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# --- Configuration ---\n# List the filenames of the submission files you want to average.\n# MAKE SURE YOU HAVE RUN THE OTHER SCRIPTS TO GENERATE THESE FILES FIRST!\nfiles_to_ensemble = [\n    '/kaggle/input/finale/submission_tabpfn_featured.csv',          # From the original simple script\n    '/kaggle/input/finale/submission_v3_kfold_lgbm.csv',   # From the K-Fold LightGBM script\n    '/kaggle/input/finale/submission_v4_kfold_catboost.csv'# From the K-Fold CatBoost script\n]\n\n# --- Load and Combine ---\nprint(\"Loading submission files for ensembling...\")\n# Load the first file\ntry:\n    final_submission = pd.read_csv(files_to_ensemble[0])\nexcept FileNotFoundError:\n    print(f\"ERROR: Cannot find the base file '{files_to_ensemble[0]}'. Please generate it first.\")\n    exit()\n\n# Loop through the rest of the files and add their values\nfor i in range(1, len(files_to_ensemble)):\n    file = files_to_ensemble[i]\n    try:\n        submission_to_add = pd.read_csv(file)\n        # Add the numeric columns together\n        final_submission.iloc[:, 1:] += submission_to_add.iloc[:, 1:]\n    except FileNotFoundError:\n        print(f\"ERROR: Cannot find '{file}'. Skipping it. Please generate it for a full ensemble.\")\n        # We can choose to skip or exit. For now, we'll just print a warning.\n        files_to_ensemble.pop(i) # Remove from list so our average is correct\n\n\n# --- Calculate the Average ---\n# Divide the summed values by the number of files successfully loaded\nnum_files = len(files_to_ensemble)\nprint(f\"Averaging the predictions from {num_files} models...\")\nfinal_submission.iloc[:, 1:] = final_submission.iloc[:, 1:] / num_files\n\n# --- Save the Final Ensemble ---\nfinal_submission.to_csv('submission_final_ensemble.csv', index=False)\n\nprint(\"\\nFinal ensembled submission 'submission_final_ensemble.csv' has been created successfully!\")\nprint(\"This is the file you should submit to the competition.\")\nprint(final_submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T09:27:24.393637Z","iopub.execute_input":"2025-07-20T09:27:24.393934Z","iopub.status.idle":"2025-07-20T09:27:24.444278Z","shell.execute_reply.started":"2025-07-20T09:27:24.393911Z","shell.execute_reply":"2025-07-20T09:27:24.443609Z"}},"outputs":[{"name":"stdout","text":"Loading submission files for ensembling...\nAveraging the predictions from 3 models...\n\nFinal ensembled submission 'submission_final_ensemble.csv' has been created successfully!\nThis is the file you should submit to the competition.\n   ID  BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n0   1        0.120042        0.208411        0.642177        0.698759   \n1   2       -0.733799       -0.549514       -1.105589        0.071160   \n2   3        1.714802        1.108693        1.086873        1.100502   \n3   4       -0.511516        0.411247        0.709046       -0.692952   \n4   5        0.222256       -1.202253        1.104600        0.459137   \n\n   BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n0        0.342093        0.775974        0.619755        0.440912   \n1       -0.722874       -0.084106       -1.104900       -1.080199   \n2        2.343506        1.791394        1.064277        1.825335   \n3        1.844998       -0.430841        0.691966        1.503292   \n4        2.185221        0.210053        1.073134       -0.217648   \n\n   BlendProperty9  BlendProperty10  \n0       -0.257940         0.338758  \n1       -0.764679         0.004163  \n2        0.542856         2.177156  \n3        0.603832        -0.912823  \n4       -0.472355         0.932028  \n","output_type":"stream"}],"execution_count":3}]}