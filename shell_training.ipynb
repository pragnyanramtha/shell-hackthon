{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797a43ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T13:49:30.527811Z",
     "iopub.status.busy": "2025-07-19T13:49:30.527594Z",
     "iopub.status.idle": "2025-07-19T14:50:32.536238Z",
     "shell.execute_reply": "2025-07-19T14:50:32.535248Z"
    },
    "papermill": {
     "duration": 3662.013032,
     "end_time": "2025-07-19T14:50:32.537742",
     "exception": false,
     "start_time": "2025-07-19T13:49:30.524710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Fuel Blending ML Pipeline: CatBoost MAX POWER\n",
      "CatBoost Optimizer configured for 2 trials per target with 5-Fold CV.\n",
      "====== STARTING ULTIMATE CATBOOST OPTIMIZATION ======\n",
      "  - Generating final, memory-safe features...\n",
      "\n",
      "--- Optimizing for Target: BlendProperty1 (1/10) ---\n",
      "  - Best MAPE for BlendProperty1: 8.391317\n",
      "\n",
      "--- Optimizing for Target: BlendProperty2 (2/10) ---\n",
      "  - Best MAPE for BlendProperty2: 0.595957\n",
      "\n",
      "--- Optimizing for Target: BlendProperty3 (3/10) ---\n",
      "  - Best MAPE for BlendProperty3: 1.191549\n",
      "\n",
      "--- Optimizing for Target: BlendProperty4 (4/10) ---\n",
      "  - Best MAPE for BlendProperty4: 0.396134\n",
      "\n",
      "--- Optimizing for Target: BlendProperty5 (5/10) ---\n",
      "  - Best MAPE for BlendProperty5: 0.326432\n",
      "\n",
      "--- Optimizing for Target: BlendProperty6 (6/10) ---\n",
      "  - Best MAPE for BlendProperty6: 0.772791\n",
      "\n",
      "--- Optimizing for Target: BlendProperty7 (7/10) ---\n",
      "  - Best MAPE for BlendProperty7: 1.613032\n",
      "\n",
      "--- Optimizing for Target: BlendProperty8 (8/10) ---\n",
      "  - Best MAPE for BlendProperty8: 0.801923\n",
      "\n",
      "--- Optimizing for Target: BlendProperty9 (9/10) ---\n",
      "  - Best MAPE for BlendProperty9: 1.331138\n",
      "\n",
      "--- Optimizing for Target: BlendProperty10 (10/10) ---\n",
      "  - Best MAPE for BlendProperty10: 0.485405\n",
      "\n",
      "====== ULTIMATE CATBOOST OPTIMIZATION COMPLETE ======\n",
      "\n",
      "====== GENERATING PREDICTIONS WITH OPTIMIZED MODELS ======\n",
      "  - Generating final, memory-safe features...\n",
      "\n",
      "ðŸ’¾ Submission file 'submission.csv' saved successfully.\n",
      "   ID  BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n",
      "0   1       -0.083031        0.223095        0.529507        0.655747   \n",
      "1   2       -0.525027       -0.413142       -1.027914        0.110114   \n",
      "2   3        1.319864        0.983354        1.058830        1.036686   \n",
      "3   4       -0.106039        0.432792        0.647958       -0.616373   \n",
      "4   5        0.208972       -1.204114        0.960654        0.554336   \n",
      "\n",
      "   BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n",
      "0        0.337304        0.723223        0.468022        0.345256   \n",
      "1       -0.731692       -0.041720       -0.970233       -1.001274   \n",
      "2        2.487232        1.452038        0.802533        1.907057   \n",
      "3        1.888528       -0.153732        0.449952        1.517219   \n",
      "4        1.989212       -0.092461        1.022035       -0.154110   \n",
      "\n",
      "   BlendProperty9  BlendProperty10  \n",
      "0       -0.153515         0.314877  \n",
      "1       -0.711161         0.035728  \n",
      "2        0.449945         2.171000  \n",
      "3        0.562225        -0.866717  \n",
      "4       -0.454903         0.967588  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- Environment Setup ---\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "class CatBoostOptimizer:\n",
    "    def __init__(self, n_splits=5, n_trials=100):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_trials = n_trials\n",
    "        self.models = []\n",
    "        self.scalers = {}\n",
    "        self.target_names = None\n",
    "        self.is_fitted = False\n",
    "        print(f\"CatBoost Optimizer configured for {self.n_trials} trials per target with {self.n_splits}-Fold CV.\")\n",
    "\n",
    "    # ### --- THIS IS THE FINAL, MEMORY-EFFICIENT FEATURE FUNCTION --- ###\n",
    "    def _create_hyper_advanced_features(self, df):\n",
    "        print(\"  - Generating final, memory-safe features...\")\n",
    "        df_features = df.copy()\n",
    "        fractions = [f'Component{i}_fraction' for i in range(1, 6)]\n",
    "        \n",
    "        # This is the most valuable and most efficient feature set to create.\n",
    "        # We will let the CatBoost model handle finding all other interactions.\n",
    "        for p in range(1, 11):\n",
    "            prop_cols = [f'Component{c}_Property{p}' for c in range(1, 6)]\n",
    "            df_features[f'prop_{p}_weighted_avg'] = np.sum(df[fractions].values * df[prop_cols].values, axis=1)\n",
    "        \n",
    "        for col in df_features.columns:\n",
    "            if df_features[col].dtype == 'float64':\n",
    "                df_features[col] = df_features[col].astype(np.float32)\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _objective(self, trial, X, y):\n",
    "        # ### --- THIS IS THE FINAL, ROBUST OBJECTIVE LOGIC --- ###\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 500, 4000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "            'depth': trial.suggest_int('depth', 4, 10),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 30.0, log=True),\n",
    "            'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "            'task_type': 'GPU', 'verbose': 0, 'allow_writing_files': False,\n",
    "        }\n",
    "\n",
    "        boosting_type = trial.suggest_categorical('boosting_type', ['Plain', 'Ordered'])\n",
    "        \n",
    "        if boosting_type == 'Plain':\n",
    "            params['bootstrap_type'] = trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS'])\n",
    "            params['subsample'] = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "            if params['bootstrap_type'] == 'Bayesian' and params['subsample'] < 1.0:\n",
    "                raise optuna.exceptions.TrialPruned(\"Bayesian bootstrap does not support subsample.\")\n",
    "        \n",
    "        # For 'Ordered' boosting, we don't add bootstrap_type or subsample\n",
    "        \n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        mape_scores = []\n",
    "        for train_idx, val_idx in kf.split(X, y):\n",
    "            model = cb.CatBoostRegressor(**params)\n",
    "            model.fit(X.iloc[train_idx], y.iloc[train_idx], eval_set=[(X.iloc[val_idx], y.iloc[val_idx])], early_stopping_rounds=100, verbose=0)\n",
    "            preds = model.predict(X.iloc[val_idx])\n",
    "            mape_scores.append(mean_absolute_percentage_error(y.iloc[val_idx], preds))\n",
    "        return np.mean(mape_scores)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(\"====== STARTING ULTIMATE CATBOOST OPTIMIZATION ======\")\n",
    "        self.target_names = y.columns.tolist()\n",
    "        X_featured = self._create_hyper_advanced_features(X)\n",
    "        self.scalers['feature_scaler'] = RobustScaler()\n",
    "        X_scaled = pd.DataFrame(self.scalers['feature_scaler'].fit_transform(X_featured), columns=X_featured.columns, dtype=np.float32)\n",
    "        del X_featured\n",
    "        gc.collect()\n",
    "\n",
    "        self.models = []\n",
    "        for i, target in enumerate(self.target_names):\n",
    "            print(f\"\\n--- Optimizing for Target: {target} ({i+1}/{len(self.target_names)}) ---\")\n",
    "            objective_func = lambda trial: self._objective(trial, X_scaled, y[target])\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            \n",
    "            # The 'catch' is removed to ensure pruning works correctly and other errors fail loudly.\n",
    "            study.optimize(objective_func, n_trials=self.n_trials, n_jobs=1) \n",
    "            \n",
    "            completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "            if not completed_trials:\n",
    "                print(f\"  - No trials completed successfully for {target}. This may be due to pruning. Please check parameter ranges or increase n_trials. Skipping.\")\n",
    "                self.models.append(None)\n",
    "                continue\n",
    "\n",
    "            best_params = study.best_trial.params\n",
    "            print(f\"  - Best MAPE for {target}: {study.best_value:.6f}\")\n",
    "            \n",
    "            final_params = best_params.copy()\n",
    "            final_params['iterations'] = final_params.get('iterations', 2000) + 200\n",
    "            final_params['task_type'] = 'GPU'\n",
    "            final_params['verbose'] = 0\n",
    "            \n",
    "            final_model = cb.CatBoostRegressor(**final_params).fit(X_scaled, y[target])\n",
    "            self.models.append(final_model)\n",
    "            \n",
    "        self.is_fitted = True\n",
    "        print(\"\\n====== ULTIMATE CATBOOST OPTIMIZATION COMPLETE ======\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted: raise RuntimeError(\"Must fit before predicting.\")\n",
    "        print(\"\\n====== GENERATING PREDICTIONS WITH OPTIMIZED MODELS ======\")\n",
    "        X_featured = self._create_hyper_advanced_features(X)\n",
    "        X_scaled = pd.DataFrame(self.scalers['feature_scaler'].transform(X_featured), columns=X_featured.columns, dtype=np.float32)\n",
    "        all_predictions = {}\n",
    "        for target, model in zip(self.target_names, self.models):\n",
    "            all_predictions[target] = model.predict(X_scaled) if model else np.zeros(len(X))\n",
    "        return pd.DataFrame(all_predictions)\n",
    "\n",
    "# =========================================================================\n",
    "# Main Execution Block\n",
    "# =========================================================================\n",
    "def main():\n",
    "    print(\"ðŸš€ Starting Fuel Blending ML Pipeline: CatBoost MAX POWER\")\n",
    "    try:\n",
    "        train_df = pd.read_csv('/kaggle/input/training/train.csv')\n",
    "        test_df = pd.read_csv('/kaggle/input/testing/test.csv')\n",
    "        for df in [train_df, test_df]:\n",
    "            for col in df.select_dtypes(include=['float64']).columns:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data: {e}. Please check file paths.\")\n",
    "        return\n",
    "    \n",
    "    target_columns = [col for col in train_df.columns if 'BlendProperty' in col]\n",
    "    feature_columns = [col for col in train_df.columns if col not in target_columns and 'ID' not in col]\n",
    "    \n",
    "    X_train, y_train = train_df[feature_columns], train_df[target_columns]\n",
    "    X_test = test_df[feature_columns]\n",
    "\n",
    "    # Using 2 trials for a quick test. Set back to 100 for the final run.\n",
    "    catboost_optimizer = CatBoostOptimizer(n_splits=5, n_trials=2)\n",
    "    \n",
    "    catboost_optimizer.fit(X_train, y_train)\n",
    "    predictions = catboost_optimizer.predict(X_test)\n",
    "\n",
    "    submission = pd.DataFrame({'ID': test_df.get('ID', test_df.index)})\n",
    "    submission = pd.concat([submission, predictions], axis=1)\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\nðŸ’¾ Submission file 'submission.csv' saved successfully.\")\n",
    "    print(submission.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7823452,
     "sourceId": 12405754,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7824237,
     "sourceId": 12406847,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7898717,
     "sourceId": 12513943,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3666.527918,
   "end_time": "2025-07-19T14:50:33.060662",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-19T13:49:26.532744",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
