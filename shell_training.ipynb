{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12405754,"sourceType":"datasetVersion","datasetId":7823452},{"sourceId":12406847,"sourceType":"datasetVersion","datasetId":7824237}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_percentage_error\n\n\ntrain_df = pd.read_csv('/kaggle/input/training/train.csv',skiprows=0)\n# test_df = pd.read_csv('/kaggle/input/testing/test.csv')\nY = train_df.filter(like=\"Blend\")\nX = train_df.drop(Y.columns,axis=1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T08:54:14.860136Z","iopub.execute_input":"2025-07-08T08:54:14.860422Z","iopub.status.idle":"2025-07-08T08:54:14.908820Z","shell.execute_reply.started":"2025-07-08T08:54:14.860400Z","shell.execute_reply":"2025-07-08T08:54:14.908245Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def feature_expansion(X):\n\n    x_engg = X.copy()\n    new_features = []\n    \n    for i in range(1,6):\n        fractionc = f\"Component{i}_fraction\"\n        proportionc = X[fractionc]\n        propertyc  = f\"Component{i}_Property\"\n        ComponentPropertiesc = X.filter(like=propertyc)  \n        partial_componets = proportionc.values.reshape(-1, 1) * ComponentPropertiesc\n    \n        partial_componets.columns = [f'weighted_C{i}_P{j}' for j in range(1, 11)]\n        \n        new_features.append(partial_componets)\n    \n    X_final = pd.concat([x_engg] + new_features, axis=1 )\n    return X_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T08:54:19.845470Z","iopub.execute_input":"2025-07-08T08:54:19.845756Z","iopub.status.idle":"2025-07-08T08:54:19.851231Z","shell.execute_reply.started":"2025-07-08T08:54:19.845734Z","shell.execute_reply":"2025-07-08T08:54:19.850427Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"X_final = feature_expansion(X)\nY_target = Y\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_final, Y_target, test_size=0.2, random_state=42\n)\n\nprint(f\"Shape of X_train: {X_train.shape}\")\nprint(f\"Shape of X_val: {X_val.shape}\")\n\nmodel = RandomForestRegressor(n_estimators=200, max_depth=15)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\nmape = mean_absolute_percentage_error(y_val, y_pred)\nprint(f\"\\nOur HONEST MAPE on the validation set is: {mape}\")\nreference_cost = 2.72 \nleaderboard_score = 100 - (90 * mape) / reference_cost\nfinal_score = max(10, leaderboard_score)\nprint(f\"Our estimated Public Leaderboard Score is: {final_score}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T09:11:26.660477Z","iopub.execute_input":"2025-07-08T09:11:26.660776Z","iopub.status.idle":"2025-07-08T09:11:46.727600Z","shell.execute_reply.started":"2025-07-08T09:11:26.660754Z","shell.execute_reply":"2025-07-08T09:11:46.726885Z"}},"outputs":[{"name":"stdout","text":"Shape of X_train: (1600, 105)\nShape of X_val: (400, 105)\n\nOur HONEST MAPE on the validation set is: 4.571365959732033\nOur estimated Public Leaderboard Score is: 10\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_percentage_error\n\nSHIFT_VALUE = 10 # Our magic number to move away from zero\n\n# --- 1. SHIFT THE TARGETS ---\nY_shifted = Y + SHIFT_VALUE\n\n# Your feature expansion code to create X_final goes here...\nX_final = feature_expansion(X)\n\n# --- 2. SPLIT THE DATA ---\n# Use the engineered features and the SHIFTED targets\nX_train, X_val, y_train_shifted, y_val_shifted = train_test_split(\n    X_final, Y_shifted, test_size=0.2, random_state=42\n)\n\n# --- 3. TRAIN THE MODEL ---\n# Find the best depth by looping and checking the MAPE\ndepths_to_test = [8, 10, 12, 15, 20, 25]\nbest_score = float('inf')\nbest_depth = None\n\nfor depth in depths_to_test:\n    model = RandomForestRegressor(n_estimators=200, max_depth=depth, random_state=42, n_jobs=-1)\n    \n    # Train on the shifted data\n    model.fit(X_train, y_train_shifted)\n    \n    # Predict on the validation set. Predictions will be shifted.\n    val_predictions_shifted = model.predict(X_val)\n    \n    # --- 4. SHIFT PREDICTIONS BACK! ---\n    # This is the crucial step before scoring\n    val_predictions_original = val_predictions_shifted - SHIFT_VALUE\n    \n    # We also need the original-scale true values for scoring\n    y_val_original = y_val_shifted - SHIFT_VALUE\n    \n    # --- 5. SCORE ---\n    # Now calculate MAPE using the original-scale values\n    mape_cost = mean_absolute_percentage_error(y_val_original, val_predictions_original)\n    \n    print(f\"Max Depth: {depth:2d} | Validation MAPE: {mape_cost:.4f}\")\n    \n    if mape_cost < best_score:\n        best_score = mape_cost\n        best_depth = depth\n\nprint(f\"\\nFound best depth: {best_depth} with MAPE: {best_score:.4f}\")\n\n# Now calculate the final estimated score using the best_score\nreference_cost = 2.72\nleaderboard_score = 100 - (90 * best_score) / reference_cost\nfinal_score = max(10, leaderboard_score)\nprint(f\"BEST Estimated Public Leaderboard Score is: {final_score:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T09:11:46.728714Z","iopub.execute_input":"2025-07-08T09:11:46.729071Z","iopub.status.idle":"2025-07-08T09:12:35.955696Z","shell.execute_reply.started":"2025-07-08T09:11:46.729045Z","shell.execute_reply":"2025-07-08T09:12:35.954953Z"}},"outputs":[{"name":"stdout","text":"Max Depth:  8 | Validation MAPE: 5.0259\nMax Depth: 10 | Validation MAPE: 4.8616\nMax Depth: 12 | Validation MAPE: 5.3986\nMax Depth: 15 | Validation MAPE: 5.0185\nMax Depth: 20 | Validation MAPE: 4.8514\nMax Depth: 25 | Validation MAPE: 4.8514\n\nFound best depth: 20 with MAPE: 4.8514\nBEST Estimated Public Leaderboard Score is: 10.00\n","output_type":"stream"}],"execution_count":40}]}